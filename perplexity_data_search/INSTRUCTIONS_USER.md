# INSTRUCTIONS_USER

## Что сделал код-агент
Код-агент создал прототип системы интеллектуального поиска по каталогу дата-продуктов с такими этапами:
1. Декомпозиция сложного запроса на подзапросы (GigaChat).
2. Извлечение сущностей/тегов для фильтрации.
3. Гибридный ретривал BM25 + Chroma vectors.
4. Объединение результатов через RRF.
5. Переранжирование кандидатов cross-encoder моделью.
6. Синтез финального объяснимого ответа (без передачи полного EDA).

> Важно: генерация каталога (`data/synthetic_catalog.json`) **не автоматизирована** и является ответственностью пользователя.

## Шаг 1. Установка Python 3.11 и создание venv
```bash
python3.11 -m venv .venv
source .venv/bin/activate
python --version
```
Ожидаемая версия: `Python 3.11.x`.

## Шаг 2. Установка зависимостей
```bash
pip install --upgrade pip
pip install -r requirements.txt
```

## Шаг 3. Скачивание локальных моделей
Скачайте и положите модели в каталог `models/` (или укажите свои пути в `.env`):
- Embedder (`SentenceTransformer`), например multilingual E5.
- Reranker (`CrossEncoder`), например `ms-marco-MiniLM-L-6-v2`.

Пример структуры:
```text
models/
  multilingual-e5-base/
  ms-marco-MiniLM-L-6-v2/
```

## Шаг 4. Сертификаты GigaChat и настройка .env
1. Скопируйте шаблон:
   ```bash
   cp .env.example .env
   ```
2. Заполните в `.env`:
   - `GIGACHAT_CREDENTIALS`
   - `GIGACHAT_SCOPE`
   - `GIGACHAT_CA_CERT_PATH` (если нужно)
   - `GIGACHAT_CERT_FILE`, `GIGACHAT_KEY_FILE` (если требуется mTLS)
3. Убедитесь, что пути к моделям/каталогу корректны.

## Шаг 5. Генерация тестового каталога (делает пользователь)
Создайте файл `data/synthetic_catalog.json` в формате массива объектов.

Рекомендуемые параметры генерации:
- 30–100 продуктов для первого прогона.
- У каждого продукта обязательно: `id`, `name`, `description`, `tags`, `eda`.
- Опционально: `generated_questions`.

Пример формата:
```json
[
  {
    "id": "dp_001",
    "name": "Credit scoring events",
    "description": "События скоринга клиентов",
    "tags": ["кредиты", "скоринг", "физлица"],
    "eda": "Витрина содержит признаки образования, региона, возраста и целевой метки default...",
    "generated_questions": [
      "Какие данные есть по скорингу и образованию?",
      "Есть ли разрез по регионам?"
    ]
  }
]
```

Пример промпта для генерации synthetic data в внешнем LLM:
- "Сгенерируй 50 синтетических дата-продуктов банка в JSON-массиве. Для каждого: id, name, description, tags[], длинное поле eda (5-10 абзацев), generated_questions[] (3-5 вопросов)."

## Шаг 6. Запуск приложения
Из корня проекта:
```bash
python src/main.py
```

Что произойдёт:
- При первом запуске, если индексов нет, система построит BM25 и Chroma индексы.
- Затем откроется интерактивный режим с приглашением `>>>`.

## Шаг 7. Примеры запросов
- "Найди данные для отчёта о зависимости кредитного скоринга от образования и локации"
- "Какие продукты подходят для анализа просрочки по сегментам дохода и регионам?"
- "Нужны источники для сравнения дефолта по возрастным группам и типу занятости"

## Возможные проблемы и решения
1. **`Catalog not found`**
   - Проверьте `CATALOG_PATH` и наличие `data/synthetic_catalog.json`.
2. **Ошибка загрузки модели**
   - Проверьте `EMBEDDER_PATH` / `RERANKER_PATH`.
3. **Ошибка GigaChat**
   - Проверьте credentials/сертификаты.
   - Увеличьте retry-параметры в `.env`.
4. **Медленная работа**
   - Уменьшите `BM25_TOP_K`, `VECTOR_TOP_K`, `FINAL_CANDIDATES_COUNT`, `MAX_EDA_CHUNKS_IN_CONTEXT`.

## Настройка производительности
Основные параметры в `src/config.py` и `.env`:
- `CHUNK_SIZE`, `CHUNK_OVERLAP`
- `BM25_TOP_K`, `VECTOR_TOP_K`
- `FINAL_CANDIDATES_COUNT`, `RERANK_TOP_K`
- `MAX_EDA_CHUNKS_IN_CONTEXT` (критично для скорости синтеза)

## Переход на реальные данные
1. Подмените `synthetic_catalog.json` на выгрузку реального каталога в том же формате.
2. Обновите `tags`, `description`, `eda` более качественными полями.
3. Перестройте индексы (удалите старые в `indices/` и запустите `python src/main.py`).
